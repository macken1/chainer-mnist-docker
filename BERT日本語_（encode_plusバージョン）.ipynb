{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT日本語 （encode_plusバージョン）",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXGb8dDXM4Zbg7Ttb8358S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macken1/chainer-mnist-docker/blob/master/BERT%E6%97%A5%E6%9C%AC%E8%AA%9E_%EF%BC%88encode_plus%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jLSiVoAmcln",
        "colab_type": "text"
      },
      "source": [
        "# **BERTを使って文をベクトルで表現してみる**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kBMtIemhcCG",
        "colab_type": "code",
        "outputId": "0e9f826a-8b02-422d-8080-529eaee02e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "## 以下、Mecabを入れとかないとTokenizerでエラーとなるのでインストールしておく\n",
        "## 乾研のBERTではmecab-ipadic-2.7.0-20070801との要件になっているが、最新版をインストール。影響は不明\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
            "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
            "W: Could not lock the cache file; this usually means that dpkg or another apt tool is already installing packages.  Opening in read-only mode; any changes you make to the states of packages will NOT be preserved!\n",
            "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw2Q3gVqmrw2",
        "colab_type": "text"
      },
      "source": [
        "## 1. 形態素解析（単語に分割する）ツールのMeCabをインストールする\n",
        "\n",
        "Google colaboratory環境に、MeCab関連のツール（MeCab単体＋辞書、MeCabをpythonから実行）などをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JknZqHhorilg",
        "colab_type": "code",
        "outputId": "6ff6f255-98d9-48ce-fa8d-d3226fa9fe03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "source": [
        "# coding: utf-8\n",
        "# 念のため、形態素解析ができるかチェック\n",
        "\n",
        "import MeCab\n",
        "\n",
        "m = MeCab.Tagger(\"Owakati\")\n",
        "print(m.parse(\"私はKARAが大好きだった。コンサートに行ったころが懐かしい。\"))\n",
        "print(m.parse(\"コロナウイルスとプロスペクト理論に悩む今日この頃\"))\n",
        "print(m.parse(\"すもももももももものうち\"))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "KARA\t名詞,固有名詞,組織,*,*,*,*\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "大好き\t名詞,形容動詞語幹,*,*,*,*,大好き,ダイスキ,ダイスキ\n",
            "だっ\t助動詞,*,*,*,特殊・ダ,連用タ接続,だ,ダッ,ダッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n",
            "コンサート\t名詞,一般,*,*,*,*,コンサート,コンサート,コンサート\n",
            "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
            "行っ\t動詞,自立,*,*,五段・カ行促音便,連用タ接続,行く,イッ,イッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "ころ\t名詞,非自立,副詞可能,*,*,*,ころ,コロ,コロ\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "懐かしい\t形容詞,自立,*,*,形容詞・イ段,基本形,懐かしい,ナツカシイ,ナツカシイ\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n",
            "EOS\n",
            "\n",
            "コロナ\t名詞,一般,*,*,*,*,コロナ,コロナ,コロナ\n",
            "ウイルス\t名詞,一般,*,*,*,*,ウイルス,ウイルス,ウイルス\n",
            "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
            "プロスペクト\t名詞,固有名詞,一般,*,*,*,*\n",
            "理論\t名詞,一般,*,*,*,*,理論,リロン,リロン\n",
            "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
            "悩む\t動詞,自立,*,*,五段・マ行,基本形,悩む,ナヤム,ナヤム\n",
            "今日\t名詞,副詞可能,*,*,*,*,今日,キョウ,キョー\n",
            "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
            "頃\t名詞,非自立,副詞可能,*,*,*,頃,コロ,コロ\n",
            "EOS\n",
            "\n",
            "すもも\t名詞,一般,*,*,*,*,すもも,スモモ,スモモ\n",
            "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
            "もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n",
            "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
            "もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n",
            "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
            "うち\t名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n",
            "EOS\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YQ_SX1m2Ek",
        "colab_type": "text"
      },
      "source": [
        "Colabでグラフ表示する際に文字化けしないように、必要なライブラリをインストールします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGZI6iaMpqDF",
        "colab_type": "code",
        "outputId": "d85f9a03-b7f1-49ae-aa51-703922a3d046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#　以下はmatplotlibでの日本語表示用のライブラリ\n",
        "!pip install japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib \n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(font=\"IPAexGothic\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.6/dist-packages (1.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ot0imlwjApw",
        "colab_type": "code",
        "outputId": "2f40a546-5246-4c9e-eccb-d11e0d612eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "import transformers as ppb\n",
        "\n",
        "# 東北大学乾研が作成した学習済みの日本語BERTモデルの形態素解析モデルを搭載します。\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O3eAgEPnV5-",
        "colab_type": "text"
      },
      "source": [
        "参照用にBERTモデル内の語彙（形態素）をvocabulary.txtに書き出します。<br>左のウインドウからvocabulary.txtをダブルクリックすると内容が確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRf7NXJGgsnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write all tokens in vocabulary.txt, which you can find on the left-hand side\n",
        "with open(\"vocabulary.txt\", 'w') as f:\n",
        "    \n",
        "    # For each token...\n",
        "    for token in tokenizer.vocab.keys():\n",
        "        \n",
        "        # Write it out and escape any unicode characters.            \n",
        "        f.write(token + '\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seprombPowgF",
        "colab_type": "text"
      },
      "source": [
        "辞書に含まれている形態素の長さ（＝文字カウント）について分布をみてみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjvrWcNTdkAW",
        "colab_type": "code",
        "outputId": "21df1774-88ac-44ce-806e-5345acb37dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid',font=\"IPAexGothic\")\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5,font=\"IPAexGothic\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Measure the length of every token in the vocab.\n",
        "token_lengths = [len(token) for token in tokenizer.vocab.keys()]\n",
        "\n",
        "# Plot the number of tokens of each length.\n",
        "sns.countplot(token_lengths)\n",
        "plt.title('形態素の長さの分布')\n",
        "plt.xlabel('形態素の長さ')\n",
        "plt.ylabel('形態素数')\n",
        "\n",
        "print('最大の形態素長:', max(token_lengths))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最大の形態素長: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAFhCAYAAAARNkAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzde3zP9f//8dvOwxx2eE+jJIfvnGITPs2popzPx1EO0caHsYhQKiExOc5xEilGZKk5FeVU+RQhcyyHRI57Gzuw2d7v3x8ue/2828Gbxib36+XSxfZ6Pd7P1/P51uXSvefz9Xy9HKxWqxURERERETs45ncHREREROTBofAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyLyr3P9+vX87oKIyL+Wc353QETkbixfvpxKlSoREBBgc3zbtm2Eh4ezbt06PD09SU9Px8PDg7/++os2bdrw3XffUbRoUQCOHz/O448/jpOTk13XHDx4MH5+fowaNSrPx2OPr776yu5g3LZtW1xdXe2qzcjIsPs7uJcuX76Mp6en8fuff/6Jh4eHzTF7rV69moSEBPr06ZOXXRQRFB5FpAAYPHgwGzduzLVm8+bNPProowD8+uuvjB07ljfeeMMmPKalpTF58mRCQkLw8/Nj1qxZbN26lY8++giLxUJiYiKff/45v//+Oz///DPx8fEMGzaM4OBgow2r1UpaWlq2fUhKSiI5OZnU1NRsz7u5ud3p0O/IxIkT8fT0pGTJkretbd68uV3hce7cuXzzzTesXr06L7p41y5evEjjxo0ZM2YMHTp0ICMjg1deeYWaNWvy/vvv33F7CxYsoGbNmvegpyLioIeEi0h+M5vNpKSkEBERAcDrr79OXFwc4eHhbN68GYBHHnkEZ2dnzpw5Q3BwMP7+/ixYsAAHBwcAvvjiC3744Qc2bdpEv379SE1N5erVq6xatYoKFSowfvx42rZtS48ePahcuTKVKlWiUqVKfP/99zg5OVGvXj0ATp8+TePGje9qHFu3buWRRx7J8fzOnTvZsmULR48eJSEhAVdXV8qVK0ejRo1o1KgRjo6530lUr149Xn31VTp37nxX/cvOb7/9RuvWrVm8eDFPP/20cfzPP/+kcOHCeHt737aNfzougGnTprF48WK+++47vLy8gJuzyKGhoXzyySfUrl3b7jEdPHiQ9u3bs2jRIurWrWv350TEPpp5FJF85+XlhZeXF4ULFwbg0Ucf5dy5c8bPmY4ePcp///tffHx8mD59uhEcAZKTk/H29ubll1/Gzc0NX19fvLy86Ny5MytWrODq1asA1KxZk7Jly2K1Wvn555+ZM2cOVapUMcLjo48+ypEjR7LtZ9++fSldujRjx469o/GdOHGCkSNHcvToUZ555hk8PDz46aefePvtt9mzZw+vv/46ZcqUYcaMGTz++OO5tjV69GhGjx6da82oUaPo3bu3XX2rWLEizz//PLNnz6ZatWrs2LGDr776im+//ZaOHTsyfvz4ez6u06dPs2TJEl566SUjOAI0bNiQli1bMnToUFavXo3JZMry2cjISGbNmpVtuy+//HKuYy9dujTffvttrjUikpVmHkWkwBg5ciRwc3l2165dvPjiixw5cgSLxcKKFSuIiIigSpUqzJo1C09PTzZt2kTDhg2N5dkePXpw+fLlLO2+88471KpVizfeeIMDBw4Yy86urq74+voydOhQqlatatRv3ryZQYMGZWnHYrEAZDuTNnfuXJ555pksx/ft20efPn2oXbs2Y8aM4ZFHHmHKlCls3LiRr7/+GoBLly7x2muvceTIEVauXMljjz2W7fdTr149QkJCaNOmTa7fY5EiRbJdQk9OTubcuXPcuHGDa9eucfXqVU6fPs3333/P5s2bcXFxoXDhwgQFBdGiRQuee+65HJe+83Jcffv25ciRI6xfv964HzVTUlISHTt2xNPTk4ULF1KkSBGb82az2ebv/OTJkwwcOJB33nmHOnXqsH37dsqWLZvttV1cXChTpkyu36WIZKWZRxEp8NasWcO4cePo1asXQ4YMwdXVla+//prBgwfbLLceP36cyZMn2yxVNmrUiKSkJODmrN3fw8ffpaamUr9+ffbs2ZPl3H//+19KlSrFW2+9leNnbw1t8fHx/Pe//+X555/n/fffN0LnH3/8YRNmfHx8mDNnDh06dGD06NF8/PHHdn4zdyY5OZl27drh5uZGoUKF8PLyolSpUpQuXZratWtz+fJl1qxZg7Nz7v9pyMtxTZ06lR07djB37twswRHAw8ODWbNm8eKLL9KnTx8WLFhAsWLFjPOZs9aZJkyYQJ06dejWrRsAISEh9OnTh2efffaOvisRyZnCo4jkK6vVSkpKCgDp6ekANptSkpOTadKkCU8++SQVKlQA4NSpU7zzzjsEBwfb3KcHMHv2bJYvX278bjabAThz5gyNGzfm559/plixYiQnJ7N161YCAwPx8/Mzrl+9evXb9nnlypU5njtw4IARviIjIylUqBDvvvuuzWxlXFwcrVu3tvlckSJF6NmzJ2PHjuXUqVM5zoi9//77t91AktOyta+vL/v378/2M3/99RctWrRg9erVdOnSJdf282pcCxcuZP78+YSEhNCoUaMcr1exYkU+/PBDXn75ZTp37syUKVOoVq1alrpFixaxb98+1qxZk2v/ReSfUXgUkXyVGepu9dVXXxk/Z+6YDQsLY9CgQZw/f56XX36ZsmXLGsvct+rQoYPNDuy/zyB+8MEH/P777xw4cIBHHnmE4OBg4944Z2dnDhw4YNQmJCRQokQJAKZMmcL+/ftZtGgRDg4O7N27Fz8/vyw7nzODY1paGrGxsfTv3x93d3fj/Llz5zhz5gw1atTI0vfM4HrkyJEcw+P48ePzdMNMplKlStG/f38mT57Mc889l+39hZA347JYLLz11lusWrWKdu3asWDBAhYsWJBr/1xcXFi5ciUDBw4kPDycDRs24OLiYpzfunUrH3zwAenp6VmC6Lhx4xg3bpzNsf79+zNkyJDcvxQRyZbCo4jkKz8/P3bs2AHc/I+8q6srI0aM4Pfff6d3795s2LABDw8PChcuzO7duwkPD8fb25t58+bh5uZGUlISHh4eRnuzZ882Nt4AWe6B9PX1pVGjRlSuXJmSJUvy008/sWvXLmrVqgX8//CXmppKcHAw1apVo1y5cnzxxRd8+OGHuLi4sHXrVgYNGkTfvn3p0aMHJUqUyHIf5KlTp0hMTMyyS/jbb7/Fzc0ty4wpYPQ7cyYWwN/f36bGng0zt8pp8w/cnPWNj48nNTUVLy8vQkJC+PHHHxk2bBgfffRRts9+zItxOTo64uPjw9tvv01wcDChoaFGbc+ePWnWrBndu3c3jsXGxrJ06VIqV67MqlWrOH/+fJbgGBYWRqlSpXB0dGTOnDnGud69e9OxY0ebGdHhw4fn+J2IyO0pPIpIvnJycjJmudLS0vDz88NkMnHp0iUAvL29SU9PZ9q0aURHR/Pss88SERFBkSJFWLp0KXPnzmXdunXGfXDjx4+nbt26nD9/niJFitCkSRMcHR2NcPfUU09RsWJFHBwcOHbsGPPmzcPX19cIj5nc3NxYuHAhAwcOZP369SxdupSqVauybt06Ro4cSb9+/ejfvz+dO3fG09OTqVOnUrx4cePzmbu7bw22ADExMdSvX98m4GY6ffo0cDPgZtq6davxc/v27enbty+tWrUCYM6cOcTFxdmEJYvFQmRkJNWqVcvxkUOnTp1i9uzZbNiwweah4yaTiWrVqvHdd98xderUbENWXo3r1lm/8uXLAzc3x8THxxMYGGgcA3B3dzfa/fs9jh9//DGTJk2iW7dulCpVipiYGJvPuri44OPjY3PsXj+PU+TfTq8nFJECIyEhIUsoAdi4cSNr165lzJgxzJo1iyJFinDs2DEmT55Mhw4dbDZQZBo9ejRPP/00GRkZlC9fHl9fXwIDAwkJCaFevXrUrVuXtm3bcubMGZtZKbPZzIULF4zZrYiICCpUqMCoUaOYOXMmr732Gh07dqRq1ap8/fXXNG3alP/973907dqV8+fPG+1kBqXM4AQ3l9B//fVXYzPH38XGxuLm5maz9PvII48Y/zg6OlK8eHHj9//+978cP36cXbt28cgjj1CoUCHGjh1rPFA9u2dOms1mgoODSU5O5pNPPmH37t3s37+fHTt2MHnyZJ544gk8PT1Zt26dsdHoVnk1ruzs3LkTq9VKYGCgzfGrV69mu5kmIyODTZs20bNnzzuajRWRf0YzjyJSIFgsFo4cOUKPHj2ynOvWrRtt2rQxdkqfPXuWV155BX9/f8LCwoy6qKgofHx8ABg0aBDPPPMMHTp0oGfPnoSEhBgbaW7cuMHJkydJSEjIsvw6evRo48HkmVxdXSlcuDBRUVF4e3tz6tQpvvjiC4oXL06JEiUYMWIEX3/9NUOHDmXp0qXAzedFlitXji+//JJnnnkGi8VCREQE1apVo379+lnGuGnTJmJjY+nRo0e2s3fZ8fPzY+jQobz55pskJCSwYMEC/Pz8+Pzzz3N8LM6mTZu4du0a06dPt9lVbTKZMJlMBAUFMXDgQFJTU7MN8vdyXCtXrqRq1aqULl3a5rjZbM42PDo5ObFgwQKbey9F5N5TeBSRAuHgwYOkpKRQpUqVbM9nBsc//viD0NBQChUqxLx582yeQ1isWDFeeOEFli1bxi+//GI8eDo4OJghQ4YQERFBq1atcHFxYffu3bz//vtERUXxn//8x2hj0qRJXLt2DVdXV9LT04mOjqZ58+ZUqFCBHj16UKZMGd577z3++OMPJk6cyFNPPUWrVq1o27atzb2KcPO1i6+++ir+/v4cP36c/fv3s3TpUpuHmyclJbFw4UKioqKoWrUqQ4cOvaPvrXv37vz++++MGzeORo0aMXv27Fzf6FKoUCGuX7/OpUuXcnwbjoeHR7bB8V6Oa/v27WzZsoUpU6ZkOXfhwoUc329tb3BMS0vjypUrFC1aFLPZbNNXEbkzCo8iUiAsX76cKlWq8MQTT+RY89133/H6669TunRp5s+fnyVQzJw5k8cff5xq1aqxa9cu43inTp04d+6ccR9l3759ad26NT179mTgwIGsWrWKsmXLAlC0aFGKFi3KwYMHGTp0KA4ODrRt2zZLX0qVKsV//vMfxo8fz/z58xk9ejRBQUE2Nc2bN+fo0aNMmzaNQoUKERERQY0aNUhLSzMC7vbt27l+/TqdO3dm1KhRtw1DaWlp/PTTT+zcuZMdO3bw2GOP8cEHH+Dt7c3cuXMZMmQI4eHhlCtXLtvPv/DCC1SoUIFevXoxYMAAqlWrhq+vL4UKFcLBwYGkpCTjYeE5yetxHTp0iNdee43nn3/euJ/zVmfOnPnHrxnMfH5npkqVKv2j9kQeZgqPIpLvjhw5wpo1a3j33XezPX/69Gnef/99Nm3aRIsWLZgwYQKFChWyqVmxYgVffvklc+fOBW5ulDCbzezcuRMfHx+aN29OamoqGzdu5JdffuGFF17g1VdfZdeuXQwaNIjPP/8cV1dXjh8/zvTp0/nmm29o1qwZY8eOzXbJ1MXFhd69e9O6dWtGjhxJ7969GTJkCP3797epCw8Pp1evXhQuXNiYJXV1deXw4cOcOXOGnj170qFDhxxf32c2m9m2bRsHDx4kMTGRsWPHUqRIEerXr8+LL77Is88+i4ODA+Hh4dSrV4/x48fTokUL4y0xf3+sj7u7O9HR0SxcuJAFCxZw7Ngx4805t/Z5wIABufyN/fNxAUbYnD59OgEBAca7zdetW0eJEiXw8vJi7969nDhxItvbGf6uTp06Oc5QFi1alA0bNpCWlkaJEiWyPGJJROyn8Cgi+e6TTz6hdu3atG/fPtvzGRkZnD17lrlz5+b4MGlHR0f69OljnG/QoAHLly+nX79+XL9+HQcHB1xdXSlevDg1a9akSZMmODk5ERERwaFDh4wAVKxYMVxcXFiyZEmW+yGz4+3tTVRUFDExMbzwwgvZ1mQ+K/JWEydOvG3bmWN/7733qFq1KqGhodSpU4eAgIBsXxtYq1YtYmJi2Lp1KytXruTMmTPZtunh4UF4eDjh4eHcuHGDhIQErl27Rnp6Os7Ozja7mXPzT8aVmppKmzZtOH/+PKGhoYSGhhr3YO7atYvY2FiSkpJwdHQkMDCQli1b3rbNJ598kieffDLH87nNaouI/fRuaxHJdykpKaSkpBibXcSWxWLJ9T7GB9WRI0coWbJktiFURAouhUcRERERsdu/739lRUREROSeUXgUEREREbspPIqIiIiI3bTb+j67fDkZi0W3mYqIiEjB5ejogKdnkWzPKTzeZxaLVeFRREREHlhathYRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERu+kNM1LgeRZ3xdnV7b5eMz0tlctX0u7rNUVERB4ECo9S4Dm7uvFjVKv7es2g0FhA4VFEROTvtGwtIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdCkR4PHr0KO+++y4BAQGsWbMmv7sjIiIiIjnI1/D4559/0rRpU1q3bs2mTZu4du1ajrUrVqygXbt2BAQE8J///Ifhw4dz8eLFLHUnT55k4MCBBAUFUbt2bQYPHszZs2ez1KWmphIZGUnTpk2pUaMG7du355tvvsn22jt27CA4OJjAwEAaNGjApEmTSE1NvfuBi4iIiDyg8jU8+vr60qlTJ9auXUt0dHSOddOmTWPixIm0bduWTz/9lHfffZc9e/bQp08fbty4YdQdP36cTp06kZ6ezuzZs5k5cyZnz54lODgYs9ls1FksFsLCwlixYgXh4eEsW7aMp59+mkGDBhEbG2tz7djYWF555RWeeuopli5dysiRI1mzZg1hYWFYrda8/1JERERECjDn/Ly4m5sbISEhAJw+fTrbmrNnz/Lhhx8ybtw4OnToAEC1atUoVaoUnTt3ZsuWLbzwwgsATJw4EU9PTyIjI3F1dQVgwYIFPP/883z00UcMGzYMgI0bN7Jt2zYWL15MUFAQAFWrVuXSpUtERETQvHlznJycuH79Ou+99x5t2rRh+PDhAFSpUgUvLy969+7N9u3badiw4b37gkREREQKmAJxz2Nu3N3def3112nTpo3N8XLlygFw5swZAK5cucK2bdvo2LGjERwBSpQoQYsWLfjiiy+wWCzAzdnEsmXLGsExU/fu3Tl//jzff/89cHO52mw2ExwcbFMXFBRE2bJliYmJydvBioiIiBRwBT48enp60qtXL5ydbSdJv/rqK+DmLCTAwYMHsVqtBAYGZmkjICCAixcvEh8fD0BcXFy2ddWrV8fR0ZHDhw8bdY6OjtSoUSNLbWBgIIcOHfpngxMRERF5wOTrsvXd+uyzzxg/fjxt2rShVq1aAMY9jT4+PlnqTSYTABcuXMBkMmE2m7Otc3JywtvbmwsXLhhtenl54eTklG2bmXV3wtvb444/I/nDZCqa310QEREpcB6o8JicnMzbb7/NunXr6NevH4MHDzbOZc5MOjg4ZPlc5rHMDS7Ozs7Z1mXKrHNxccmxzsHB4a42zMTHJ2GxaKPNncivEHfxYmK+XFdERCS/OTo65Djh9cCExz///JN+/fphtVqJjo4mICDA5ryvry8A8fHxxv2QmTJnJUuWLGnUXrp0Kcs1LBYLCQkJNnVmsxmLxYKjo+0Kv9lsNupEREREHhYF/p5HgHPnztGzZ08qVapETExMluAINzfQuLi4sHfv3izn9uzZg4+PD97e3gBUqlSJffv2ZamLi4vjxo0b+Pv7G3UZGRnExcVl22ZmnYiIiMjDosCHR6vVyquvvkrlypWZMmUK7u7u2dYVL16cRo0asXr1aptnPyYmJrJ+/Xratm1rzB62b9+eY8eOsWvXLps2PvvsM0wmE/Xr1wegXr16mEwmVqxYYVO3e/dufv/9d+PRQSIiIiIPiwK/bL1+/Xr279/Pxx9/zPHjx7OcL1SoEKVKlQJg8ODBdO7cmcGDBxMaGsr169eZMWMGzs7O9OnTx/hMw4YNqVu3LkOGDOGNN96gTJkyrF+/npUrVzJp0iRjg4yzszPDhg1j5MiReHt706xZM06ePMmECROoW7cuDRo0uD9fgoiIiEgBUeDD47Fjx0hPT+fFF1/M9nydOnX45JNPAKhQoQLR0dFMnjyZPn364OzsTFBQEFOmTLHZXe3o6MicOXOYPn06EyZM4MqVK5QvX54ZM2bQrFkzm/bbtWuHu7s78+fPZ/HixRQvXpxWrVrx6quvZrkPUkREROTfzsGqd+zdV9ptfedMpqL8GNXqvl4zKDRWu61FROShldtua02diYiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4FIjwePXqUd999l4CAANasWZPf3RERERGRHORrePzzzz9p2rQprVu3ZtOmTVy7di3H2tjYWNq3b09AQACNGzdm/vz5WCyWLHUnT55k4MCBBAUFUbt2bQYPHszZs2ez1KWmphIZGUnTpk2pUaMG7du355tvvsn22jt27CA4OJjAwEAaNGjApEmTSE1NvfuBi4iIiDyg8jU8+vr60qlTJ9auXUt0dHSOdVFRUYwcOZIWLVqwbNkyQkNDmTdvHmPGjLGpO378OJ06dSI9PZ3Zs2czc+ZMzp49S3BwMGaz2aizWCyEhYWxYsUKwsPDWbZsGU8//TSDBg0iNjbWps3Y2FheeeUVnnrqKZYuXcrIkSNZs2YNYWFhWK3WPP0+RERERAo65/y8uJubGyEhIQCcPn0625rz588zc+ZMQkJCjNoqVarg6OjI6NGj6dWrF+XLlwdg4sSJeHp6EhkZiaurKwALFizg+eef56OPPmLYsGEAbNy4kW3btrF48WKCgoIAqFq1KpcuXSIiIoLmzZvj5OTE9evXee+992jTpg3Dhw83ru3l5UXv3r3Zvn07DRs2vHdfkIiIiEgBUyDueczNhg0byMjIoEuXLjbHW7duTdGiRYmJiQHgypUrbNu2jY4dOxrBEaBEiRK0aNGCL774wljmjo2NpWzZskZwzNS9e3fOnz/P999/D9xcrjabzQQHB9vUBQUFUbZsWePaIiIiIg+LAh8e4+Li8PPzw8/Pz+a4u7s7lStX5tChQwAcPHgQq9VKYGBgljYCAgK4ePEi8fHxRpvZ1VWvXh1HR0cOHz5s1Dk6OlKjRo0stYGBgca1RURERB4W+bpsbQ+z2YyPj0+250wmE7/99ptRB2RbazKZALhw4QImkynHNp2cnPD29ubChQtGm15eXjg5OWXbZmbdnfD29rjjz0j+MJmK5ncXRERECpwCHx5dXFxwcHDI9tytx52dnbMc+3td5gYXZ2fnHNu8te52176bDTPx8UlYLNpocyfyK8RdvJiYL9cVERHJb46ODjlOeBX4ZWtfX18uXbqU7Tmz2Yyvr69RBxhL03+vAyhZsmSubVosFhISEmzqzGZzto8EMpvNRp2IiIjIw6LAh0d/f3/Onj2bZYk4PT2dX3/9FX9/fwDKlSuHi4sLe/fuzdLGnj178PHxwdvbG4BKlSqxb9++LHVxcXHcuHHDaLNSpUpkZGQQFxeXbZuZdSIiIiIPiwIfHlu2bImTkxOrVq2yOb5u3TqSkpLo0KEDAMWLF6dRo0asXr2aGzduGHWJiYmsX7+etm3b4uh4c7jt27fn2LFj7Nq1y6bNzz77DJPJRP369QGoV68eJpOJFStW2NTt3r2b33//3bi2iIiIyMOiwN/zWKJECfr168ecOXNwd3cnKCiIuLg4JkyYQMeOHalQoYJRO3jwYDp37szgwYMJDQ3l+vXrzJgxA2dnZ/r06WPUNWzYkLp16zJkyBDeeOMNypQpw/r161m5ciWTJk0yNsg4OzszbNgwRo4cibe3N82aNePkyZNMmDCBunXr0qBBg/v+fYiIiIjkpwIfHgHCwsLw9vZmyZIlTJs2DZPJREhICP369bOpq1ChAtHR0UyePJk+ffrg7OxMUFAQU6ZMsdld7ejoyJw5c5g+fToTJkzgypUrlC9fnhkzZtCsWTObNtu1a4e7uzvz589n8eLFFC9enFatWvHqq68aM5kiIiIiDwsHq96xd19pt/WdM5mK8mNUq/t6zaDQWO22FhGRh9YDvdtaRERERAoOhUcRERERsZvCo4iIiIjYTeFRREREROym8CgiIiIidlN4FBERERG7KTyKiIiIiN0UHkVERETEbgqPIiIiImI3hUcRERERsZvCo4iIiIjYTeFRREREROym8CgiIiIidlN4FBERERG7KTyKiIiIiN0UHkVERETEbgqPIiIiImI3hUcRERERsZvCo4iIiIjYTeFRREREROym8CgiIiIidlN4FBERERG7KTyKiIiIiN3uWXi8fPnyvWpaRERERPKJ3eExODiYrVu32lW7YsUKmjdvzrFjx+66YyIiIiJS8DjbW2g2m9mwYQOJiYn4+fnh7++Ph4dHlrojR44wceJEnnnmGcqXL5+nnRURERGR/GV3eAT4+eef2b59O/Hx8QCUKVOGunXr0rhxY+rXr8/Bgwfp06cPNWvWJCIi4p50WERERETyzx2Fx9dff50mTZpw7do1jh49yu7du9m2bRv9+vWjZMmSJCUl0bBhQyZOnIiz8x01fVsHDx5kzpw57Nmzh5SUFMqWLUu3bt3o2LEjTk5ORl1sbCwLFy7kxIkTeHt706VLF0JCQnB0tF2hP36tRTQAACAASURBVHnyJJMnT+aXX34hPT2doKAgRo0ahZ+fn01damoqUVFRxMbGcu7cOcqVK8eAAQN44YUX8nR8IiIiIg+CXO95/OOPP0hMTMxyvFChQtSoUYOXXnqJxo0bU6JECdLS0rh+/ToJCQmkpqbmaSf37t1L165duXLlChEREXz88cc0bNiQt99+m3feeceoi4qKYuTIkbRo0YJly5YRGhrKvHnzGDNmjE17x48fp1OnTqSnpzN79mxmzpzJ2bNnCQ4Oxmw2G3UWi4WwsDBWrFhBeHg4y5Yt4+mnn2bQoEHExsbm6RhFREREHgS5Tg8OGDCA48ePYzKZSEhI4LvvvsPLy4u//vqLHTt2sH37dooVK0ZoaCjBwcGcOnWKsLAwgoODWbRoET4+PnnSySVLluDh4UFUVBSFChUCoHr16ly+fJmVK1cyYsQIUlJSmDlzJiEhIYSEhABQpUoVHB0dGT16NL169TLuwZw4cSKenp5ERkbi6uoKwIIFC3j++ef56KOPGDZsGAAbN25k27ZtLF68mKCgIACqVq3KpUuXiIiIoHnz5jazniIiIiL/drnOPK5YsYJly5YxaNAgWrZsye7du3nppZcYMWIE33//PRMmTGDjxo306tULNzc3KlasSHR0NBaLhcGDB5ORkZEnnbx+/TqPPvqoERwzVapUCavVirOzMxs2bCAjI4MuXbrY1LRu3ZqiRYsSExMDwJUrV9i2bRsdO3Y0giNAiRIlaNGiBV988QUWiwW4uQRetmxZIzhm6t69O+fPn+f777/Pk/GJiIiIPChyDY8eHh4EBgbSuXNnhg8fzsyZM/nqq6/o168fFouFESNG8OuvvzJr1izjM15eXsybN4+jR48SHR2dJ51s164dR48e5fjx48Yxi8XCN998Q5cuXShUqBBxcXH4+flluWfR3d2dypUrc+jQIeDmvZNWq5XAwMAs1wkICODixYvGhqC4uLhs66pXr46joyOHDx/Ok/GJiIiIPChyXbY+evQo69evp3fv3vz888/ExMQwb948kpOTeeutt6hTpw6FCxema9euhIWFGZ87f/48w4cPp3PnznnSySZNmmC1Whk5ciRNmzaldOnSbNy4kZYtW9KxY0fg5qOEclomN5lM/Pbbb0YdkG2tyWQC4MKFC5hMphzbdHJywtvbmwsXLtzxWLy9sz7eSAomk6lofndBRESkwMk1PKakpLBlyxaWLVtGnz59gJuzcV9++SV9+vTBx8eHlJQUrFYrzZo1o1mzZvTu3ZuJEydSoUIFunbtmiedzMjI4Pjx4/j7+9OgQQNKlizJkSNHWLt2LQEBAVSoUAEXFxccHByy/fytxzN3gWdXm3nMarUatTm1eWvdnYiPT8JiufPPPczyK8RdvJh1s5iIiMjDwNHRIccJr1zDY0BAADExMfz4449cvnyZPXv2EBUVxfDhw7MsDw8YMICYmBiee+45HB0dmT9/fp4NYPTo0cTHxxMVFWUcCw8P58svv6Rbt27Exsbi6+trzC7+ndlsxtfXF8D4Mz4+nnLlymWpAyhZsqRRe+nSpSztWSwWEhISjDoRERGRh0Wu9zzWrl2bOnXqEB4ezptvvsmOHTvYtGkTEydOpE6dOkyaNIkTJ07g4OBAmzZtWLRoEf7+/qSnp3P16tU86WBycjIxMTE0atQoy7kmTZpw9epVvvnmG/z9/Tl79myWpeT09HR+/fVX/P39AShXrhwuLi7s3bs3S3t79uzBx8cHb29v4OaGnH379mWpi4uL48aNG0abIiIiIg+LXMPj7NmzmTVrFrNmzaJv3764uLhQqlQppkyZQmRkJHFxccbu5v/973/89ddfHDx4kJYtWzJq1Kg86aDVasXBwSHbWcU9e/YA4OLiQsuWLXFycmLVqlU2NevWrSMpKYkOHToAULx4cRo1asTq1au5ceOGUZeYmMj69etp27at8UDx9u3bc+zYMXbt2mXT5meffYbJZKJ+/fp5MkYRERGRB4XTmL8/QfsWJpOJrVu3MmPGDAIDA3FwcKBevXpER0fz8ssv8+KLL9K+fXs+/vhjtm7dypdffkndunUZM2YMkZGR1KxZM8vy9p1ydXXlwoULrFixArPZTJEiRbh06RIbN25k7NixmEwmRo8eTfHixbFYLMydOxd3d3fc3d3ZsmUL48aNo02bNjabdypWrMiiRYvYv38/pUuX5uTJk7z55pskJSUxadIkChcuDNx8/eKePXuIjo7Gz8+PtLQ0lixZwieffMI777xDlSpV7ng8166lcRe3Sj7UihRx4/TuZff1mo891Z2UlLT7ek0REZGCwsHBgcKFXbM/Z81l18f+/fsJDQ3lpZdewtvbmy1btjBv3jxGjRrFn3/+yccff0xqaipPPfUUO3fuZOrUqbRq1YratWszatQoXF1deffdd//xACwWCytXriQmJoZjx46RlpbGI488wgsvvEDfvn3x9PQ0aqOjo1myZAmnT5/GZDLRqVMn+vXrl+Vh3ocPHzZeT+js7ExQUBAjRoygdOnSNnXXrl1j+vTprFu3jitXrlC+fHn69etHs2bN7mos2jBz50ymovwY1eq+XjMoNFYbZkRE5KGV24aZXMMj3NxxXbhwYb799ltiY2OZOnUqly9fpnXr1nzwwQfUqFGDWrVqceDAAZvP7dixA3d3d2rVqpV3I/kXUHi8cwqPIiIi99c/Co85SUpKwsNDzyy8UwqPd07hUURE5P7KLTzmumEmJxaLRcFRRERE5CFkV3g8f/688XNaWhpVq1Y13v+ceb5Hjx5GXVRUFElJSXncVRERERHJb7cNj2lpaTz77LMAbNu2DbB9s8rVq1d5+eWXcXR0pEiRIuzcuZNp06axadOme9NjEREREck3d7RsPWDAAJvfrVYrQ4cO5dSpUzRp0oQiRYowfvx4GjZsSLt27fK0oyIiIiKS/3J9PeHf/X1vTUJCAmazmcGDB3Pp0iXWrl3LxYsXWbJkSZ52UqSgKVHcFRdXt/t+3RtpqSRc0fMnRUQk/9xReHRwcDB+Pn/+PKtWrWLVqlV8/fXX7Ny5k3Xr1jFgwAC8vLzyvKMiBYmLqxurFt3dsz7/iU4vbwAUHkVEJP/cUXi81ZkzZ/jwww9xcXGhcuXKXL16lZEjR1KqVKm87J+IiIiIFCB39agegJo1azJz5kzmzp3Ltm3bSExMpEyZMjg733UeFREREZECLtekN2nSJJKTkwEYM2YMFouF8ePHG8vXzzzzDO+//z7Dhg3Dx8eHt956y+bz48aNu0fdFhEREZH8kGt4PHPmjBEeT58+bRyzWq306tWLN998kxYtWnDs2DGioqI4efKk8dlb748UERERkX+HXMPjzJkzSU1NJSAggA8//JBq1aoxd+5cqlevzpNPPknfvn2JjIzkq6++wsPDg08++eR+9VtERERE8sFtb1DMaQZx2LBhuLu78+KLL1K+fHlSUlI4duwYrq6uPPbYY3neURERERHJf3e1YSYzUJ44cYIKFSowefJkUlNTWb9+Pf3799erCUVERET+pe56t3VCQgJxcXHMmTOHEiVK4ODgQLdu3cjIyOCdd97Jyz6KiIiISAFxR+Ex8w0zVquVEiVKsHbtWh577DEcHW824+LiwtSpU1m/fj27d+/O+96KiIiISL6yKzxmhsbIyEjg/y9bu7q63mzE0RGr1UpaWhpVqlTh+eefJzo6+l70V0RERETy0W03zLi6urJ582YAGjVqRFpaWpZ3XDs5OdG4cWPc3d0BGDJkCMWKFbsH3RURERGR/GTX62BKly5t/Ozq6sqBAweMpWoALy8vZs+ebfz+xBNP5GEXRURERKSguKsNM05OTrmeT09Pv6vOiIiIiEjBZld4/OGHHxg/fjyHDh2yOb5r1y5GjRrFjz/+aBw7deoUHTp0YNOmTXnbUxERERHJd7mGR4vFwmeffUZGRgYHDhxg6tSpAJw7d47FixdjtVq5cOEC7777LgA//fQTHTt2xMPDg8qVK9/73ouIiIjIfZXrPY9//PEHH3zwAf/73/9wcXHh/fffB+CXX35h+fLlbNiwAS8vL9q1a8euXbsIDQ2lV69ehIeH29wTKSIiIiL/DrkmvCeeeAJPT08OHz5MsWLFSE1NBeCZZ57h3LlzXLx4EU9PT9LT0/H09GTUqFGUL1+eVatWcfny5fsyABERERG5f247PVinTh0OHz5s847rIkWKULVqVQ4ePGg8tqds2bJ07dqVL7/8kvfff58RI0bcu16LiIiISL7Iddk6KSmJChUqcPDgQdzd3Y3nOCYlJVG+fHni4uJwc3PD2dnZ2IH94YcfsnHjRiZMmHDvey8iIiIi91Wu4fG5554jMTERgE8//ZQOHTqQkpJCrVq1bOoCAwMBWLduHZcuXaJ27dpcuXLlHnVZRERERPJLruHxyy+/xGKxkJiYSGJiIrVr1wYw3jgDN19N6Ovry9dff83w4cMZOHAgrq6upKWl5Xlnd+7cSWRkJAcOHMDZ2ZkaNWrw6quv8uSTTxo1sbGxLFy4kBMnTuDt7U2XLl0ICQnJsoHn5MmTTJ48mV9++YX09HSCgoIYNWoUfn5+NnWpqalERUURGxvLuXPnKFeuHAMGDOCFF17I8/GJiIiIFHS5hkc/Pz+SkpIYMmQI1atXx8HBgeTkZJuazPdaL1iwgLFjx9KxY0eOHTuW5RWG/9R3333H0KFD6devH2+++SYpKSl8+umn9O3bl/Xr1+Pt7U1UVBQzZ84kPDycevXqsX//fiZOnMiZM2cYO3as0dbx48fp0qULTz31FLNnzyY1NZWpU6cSHBxMTEwMXl5ewM1HFYWFhXHo0CHeeOMNHn/8cWJjYxk0aBAffPABrVq1ytMxioiIiBR0uYbH5ORk+vTpw2+//cb48eN57bXXSE5O5vLlyxQtWpTLly9TrFgxrFYr3377rXFP5KVLl4yf88L169cZPXo0r732Gi+99JJxvGbNmly+fBlvb2/Onz/PzJkzCQkJISQkBIAqVarg6OjI6NGj6dWrF+XLlwdg4sSJeHp6EhkZiaurKwALFizg+eef56OPPmLYsGEAbNy4kW3btrF48WKCgoIAqFq1KpcuXSIiIoLmzZvf9m07IiIiIv8mue62dnZ2pmHDhnTu3Jlz584B8O2339KgQQMWL15M2bJl2bhxI1evXuXzzz+ncePGNG7cmP79+/PYY4/lWSc3bdpEYmIinTp1su28oyPe3t4AbNiwgYyMDLp06WJT07p1a4oWLUpMTAwAV65cYdu2bXTs2NEIjgAlSpSgRYsWfPHFF1gsFuDmEnjZsmWN4Jipe/funD9/nu+//z7PxigiIiLyIMg1PCYkJBAWFkbRokUxm83G8Vsf25OSkkLdunV58skn6dmzJz179mTYsGHMnj07zzq5a9cunnjiCS5evEj//v2pVasW9evXZ/z48aSkpAAQFxeHn59flnsW3d3dqVy5svFqxczHC2Vu8rlVQEAAFy9eJD4+3mgzu7rq1avj6OjI4cOH82yMIiIiIg+CHJetU1NTadasGf3798fNzY2EhATj3K33M/r6+hIVFXWzMWdnqlSpkuedPHv2LDdu3CAkJISXXnqJfv368euvvzJ9+nROnz7NvHnzMJvN+Pj4ZPt5k8nEb7/9BmCE4OxqTSYTABcuXMBkMuXYppOTE97e3ly4cOGOx+Lt7XHHn5H8YTIVze8uZKug9ktERB4OOYZHNzc3ZsyYweTJkzl79iy9e/cG4Mcff+Ty5cvs27ePa9eusXPnTqxWK+XLl6dbt2488cQTDBkyhGeeeSbPOpmamsqxY8dYsGABDRs2BG4+HsjT05Phw4eze/duXFxcbGZEb3XrcWdn5yzH/l6XGY6dnZ1zbPPWujsRH5+ExZK3m4n+7fIrLF28mJjjufwMcLn1S0REJC84OjrkOOGV67J1w4YNWb16NY0bNyYlJYUSJUowfPhwTpw4wZQpU7h+/TrDhg1j+PDhxMfHExsbS8WKFenfvz+TJ0/OswEUK1YMLy8vIzhmatSoEXBzednX15dLly5l+3mz2Yyvry+A8Wfm0vTf6wBKlixp1GbXpsViISEhwagTEREReVjkutsawMXFhaCgIJKTk3n99ddv2+DkyZOpVatWnu5C9vf354cffsBqtWY7E2i1WvH392fVqlVcuHDBCIgA6enp/Prrr3Tt2hWAcuXK4eLiwt69e43nVmbas2cPPj4+xiacSpUqsW/fvizXi4uL48aNG/j7++fZGEVEREQeBLd9tzVAu3btePHFF7M9l5SUlOVY165ds+yM/ieaN29OcnIy69atszm+adMm4Ob7t1u2bImTkxOrVq2yqVm3bh1JSUl06NABgOLFi9OoUSNWr17NjRs3jLrExETWr19P27ZtjQeKt2/fnmPHjrFr1y6bNj/77DNMJhP169fPszGKiIiIPAicxowZM8be4rS0NHbv3k3p0qWBm8+BbNasGVevXqVWrVpZ3uKSVzw9Pbl+/TozZ86kWLFiuLi4sG3bNiZMmECzZs3o3r077u7uWCwW5s6da7yHe8uWLYwbN442bdrQuXNno72KFSuyaNEi9u/fT+nSpTl58iRvvvkmSUlJTJo0icKFCwNQpkwZ9uzZQ3R0NH5+fqSlpbFkyRI++eQT3nnnnbvaHHTtWhp5/Pz0f70iRdw4vXvZfb3mY091JyUl57ckFSnixsG9n97HHt1UJfClXPslIiKSFxwcHChc2DX7c9Zcdn3s27ePuLg4Y9Zx8+bNhIWF0b17d0aMGIGrqytLly7lgw8+oFKlSsybN4/ixYvfk0FYrVaWLl3K0qVL+fPPP/Hy8qJDhw6EhYUZm2AAoqOjWbJkCadPn8ZkMtGpUyf69euXZRn98OHDxusJnZ2dCQoKYsSIEUYwznTt2jWmT5/OunXruHLlCuXLl6dfv340a9bsrsahDTN3zmQqyo9R9/dtPkGhsbfdMLNq0d39O/BPdHp5gzbMiIjIPZfbhplcw+OKFSsYO3Ys9evXZ9q0aRQuXJivv/6aMWPGUK5cOebOnUvRokU5duwYr7zyCh4eHixcuNDmnkOxpfB45xQe/z+FRxERuR/uerd1165diY6O5tChQ/To0YMrV67QpEkTli9fztmzZ+nVqxfXrl2jfPnyLFu2jLS0NPr3709qauo9GYiIiIiI5K/b3qRYvXp1oqOjuXLlCmFhYaSnp1OmTBmWLVvGxYsXGTFiBAB+fn5ERUVx+vRp3njjjXvecRERERG5/+za4VK6dGnmzJnDgQMHmDZtGnDzWYjTp0/n22+/5fPPPwfg8ccfZ9KkSaxdu5atW7feu16LiIiISL64bXj866+/sFgs/N///R/Dhw/n448/5tixY8yaNYsqVaoQHBzM1KlTuXbtGgDPPfccjRs3JjIy8p53XkRERETur9s+JLxx48Zs3ryZUqVKERwcTKFChfDz82P27Nl069aNAQMGUKFCBQoVKmR85o033iAjI+OedlxERERE7r/bhsdb3+ri4OBAu3btSElJwWq1kpycjJeXF61atbJ5WPi9elyPiIiIiOSv24ZH+P/vkL6Vg4MDTZs2zbY+M3AeOnTon/VORERERAoUu8Lj9OnT8fHxMX6/fv06r7zyCh999BGenp73rHMiIiIiUrDYFR6rV6+On5+f8XvmsrW/vz9eXl73rHMiIiIiUrDYFR4nTpxovO8ZMDbDTJw4EW9vb4oUKUK5cuWoWrUqjz/++L3pqYiIiIjkO7vC49/fYJj5e2pqKidPniQhIYGPPvqIa9euUblyZXr27Em7du3yvrciIiIikq/sCo8jR46kVKlSxu/JycnExsby9ttv4+3tDdwMlAcOHGD58uW8/fbbxMbGEhERoWVtERERkX+R2z4kvEmTJjbPcISbO63/Phvp4OBAtWrVGD9+PCtXrsTPz89mqVtEREREHny3nXmcOXNmlmOFCxdm8+bNOc4q+vv7M27cuH/eOxEREREpUOxats5O6dKl87IfIiIiIvIAuO2ytYiIiIhIJoVHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG53/ZBwESlYipdwwdXF/b5fN+3Gda4k3Ljv1xURkfyh8CjyL+Hq4s7MpU3v+3UHv7gRUHgUEXlYaNlaREREROym8CgiIiIidnsgw6PZbKZBgwY0atQoy7kdO3YQHBxMYGAgDRo0YNKkSaSmpmapu3DhAiNGjKBBgwYEBgbSt29fjhw5kqUuIyODTz75hJYtW1KjRg2aN2/OihUr7sm4RERERAq6By48Wq1WXn/9dRwds3Y9NjaWV155haeeeoqlS5cycuRI1qxZQ1hYGFar1aiLj4+nS5cunDx5koiICD788EMcHR3p1q0bJ06csGnz3XffZerUqfTq1Yvly5fTvn17xo4dS1RU1D0fq4iIiEhB88BtmPnwww85ceIEoaGhLFy40Dh+/fp13nvvPdq0acPw4cMBqFKlCl5eXvTu3Zvt27fTsGFDAGbNmkVSUhJr1qyhePHiAMyePZuWLVsyc+ZMpk2bBsCvv/7KihUreO+99+jUqRMAlStXJiUlhVmzZhEcHEyxYsXu5/BFRERE8tUDNfO4d+9eZsyYwfjx4ylUqJDNuR07dmA2mwkODrY5HhQURNmyZYmJiQFuzlyuXbuW5s2bG8ERwNXVlU6dOrFp0yauXr0K3JzJ9PDwoFWrVjZtBgcHc+PGDdauXXsvhikiIiJSYD0w4fHq1asMHTqUHj16EBQUlOV8XFwcjo6O1KhRI8u5wMBADh06BMCff/7JlStXCAwMzFIXEBBAWloax48fN9qsUqUK7u62z8575JFH8PPzM9oUEREReVg8MMvWb775Jl5eXgwdOjTb82azGS8vL5ycnLKcM5lMXLhwwagD8PHxybYOsKmtXLlytte7tc074e3tccefkfxhMhXN7y5kqyD2qyD2SURE7o0HIjx++umnfP/993zxxRe4uLhkW+Pi4oKDg0O25xwcHIwNM87Ozsax7OoAo/Z2bd6N+PgkLBbr7QvFkF/B5OLFxBzP5WdYyqlfBbFPIiLyYHJ0dMhxwqvAL1sfPnyYSZMmMWrUKEqWLElqaiqpqamkp6djtVpJTU0lLS0NX19fzGYzFoslSxtms5mSJUsC4OvrC9zccZ1dHWBTe+nSpWz7ZTabjbZEREREHhYFPjzu3LmTtLQ0Ro8eTfXq1Y1/3nrrLf766y+qV69Os2bNqFSpEhkZGcTFxWVpY8+ePfj7+wM3l6t9fHzYu3dvtnUuLi488cQTAPj7+3Po0CHS0tJs6uLj4zl16pTRpoiIiMjDosAvW7ds2ZKAgIAsx7ds2cKqVauYNWsWrq6u/N///R8mk4kVK1ZQvXp1o2737t38/vvvvP766wA4OjrSpk0bVq9ezWuvvUbRojeX+tLT01m9ejWNGzc2dmG3b9+ehQsXsn79etq2bWu0+dlnn+Hi4pJlF7aIiIjIv12BD48mk8nYyHKr48eP4+rqahMshw0bxsiRI/H29qZZs2acPHmSCRMmULduXRo0aGDU9e3bl6+++orQ0FDCw8NxdXUlKiqKs2fPEhkZadRVrFiRDh06MHbsWNLS0qhWrRo//PADs2bNYsCAATaP+hERERF5GBT48Hgn2rVrh7u7O/Pnz2fx4sUUL16cVq1a8eqrr9q8kcbHx4fly5cTERHBoEGDSE9Pp2bNmkRHR1O+fHmbNsePH89jjz3G3LlzuXjxIo8++iijR4+mW7du93t4IiIiIvnOwXrre/vkntNu6ztnMhXlx6j7e4tAUGjsbXdbr1rU7D726KZOL2/Idbf1zKVN73OPYPCLG7XbWkTkX+aB3m0tIiIiIgWHwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN4VHEREREbGbwqOIiIiI2E3hUURERETspvAoIiIiInZTeBQRERERuyk8ioiIiIjdnPO7A1JweBV3w8nV9b5fNyMtDfOV1Pt+XREREblzCo9icHJ15a/ZQ+/7dUsNnAooPIqIiDwItGwtIiIiInZTeBQRERERuyk8ioiIiIjdFB5FRERExG4KjyIiIiJiN+22FpF7plgJV9xc3O77dVNvpHI1Ie2+X1dE5GGg8Cgi94ybixsvxzS779dd1H4DoPAoInIvaNlaREREROym8CgiIiIidlN4FBERERG7KTyKiIiIiN0emPB48eJF3nnnHRo1akS1atVo2rQpixcvxmq12tTFxsbSvn17AgICaNy4MfPnz8disWRp7+TJkwwcOJCgoCBq167N4MGDOXv2bJa61NRUIiMjadq0KTVq1KB9+/Z8880392ycIiIiIgXZAxEeExMT6dWrF/v27ePNN98kOjqa1q1bExERwYIFC4y6qKgoRo4cSYsWLVi2bBmhoaHMmzePMWPG2LR3/PhxOv2/9u48vqZr///4K6NEIiSRQ1CU3CRiiLHm9kpVEaoSIkFMacScBDUVRaMhao5QaqiZaMKlMVNt3bpmEbOoKWYRGWXcvz/8cq4jCae3nJN8fZ6Ph0dZe5293+fQnc9Za6+9u3UjJyeHRYsWsWDBAu7evYu3tzeJiYnqfnl5eQwbNoxNmzYRGBjI+vXradasGcOHD2fHjh26evtCCCGEEMVGibhVz/r160lMTCQmJgYbGxsA6taty+PHj1m6dCkDBw7k/v37LFiwAH9/f/z9/QFwcXHB0NCQiRMn0rdvX2rWrAnAjBkzsLa2ZuHChZiamgKwbNky2rZty4oVKxg9ejQAu3fv5tdff2XVqlU0b94cgNq1a/Po0SPCwsLo0KEDRkZGuv44hBBCCCH0pkSMPLZs2ZKpU6eqC8d8NWrUICUlheTkZHbtdtS+VwAAIABJREFU2kVubi5eXl4afTp37kyZMmWIjo4G4OnTp/z66694enqqC0eAcuXK0bFjR7Zu3aqe5t6xYwfVq1dXF475evbsyf379zl8+PDbeLtCCCGEEMVWiSge869xfFFubi4xMTFUrVoVKysr4uLisLe3x97eXqOfmZkZtWrV4sKFCwCcP38eRVFo0KBBgePUr1+fhw8f8vjxYwDi4uIK7VevXj0MDQ25ePHim3qLQgghhBAlQomYtn5ZSkoKY8aM4ezZsyxatAiAxMREypcvX2h/Ozs7rly5ou4HFNrXzs4OgAcPHmBnZ1fkPo2MjLC1teXBgwd/ObutreVffs27wM6ujL4jFFAcM0HxzCWZhBDi3VHiisfY2FiCg4PJzs5m5cqVNGnSBAATExMMDAwKfc2L7cbGxgXaXu6Xv4Lb2Ni4yH2+2O+vePw4lby8v/46XdDnD9uHD1OK3KavXMUxExSdSzJpetXfnxBCiFczNDQocsCrRExb54uOjqZXr1588MEHbN++XV04AqhUKh49elTo6xITE1GpVOp+gHpq+uV+ABUqVHjlPvPy8khKSlL3E0IIIYR4V5SY4jEqKoqvv/6aGTNmEBoaStmyZTW2Ozk5cffu3QJTyTk5OcTGxuLk5AQ8X2RjYmLC6dOnCxzj1KlTlC9fHltbWwCcnZ05c+ZMgX5xcXFkZ2er9ymEEEII8a4oEcXjxYsXmTJlCrNmzcLd3b3QPu7u7hgZGbFlyxaN9piYGFJTU/Hw8ACgbNmyuLm5ERUVRXZ2trpfSkoKO3fupEuXLhgaPv9YunbtSnx8PMePH9fY5+bNm7Gzs6NVq1Zv8m0KIYQQQhR7JeKax9mzZ+Pq6oqDgwPx8fEFtqtUKsqVK0dAQAARERGYmZnRvHlz4uLi+Pbbb/H09MTBwUHdf8SIEXTv3p0RI0YwcOBAnj17xvz58zE2NmbAgAHqfh9++CEtWrQgODiYCRMmULVqVXbu3ElkZCQzZ86UezwKIYQQ4p1TIorH+Ph4EhIS6NixY6HbQ0ND8fDwYNiwYdja2rJ69Wrmzp2LnZ0d/v7+BAQEaPR3cHBgw4YNzJo1iwEDBmBsbEzz5s2ZPXu2xupqQ0NDIiIimDdvHt9++y1Pnz6lZs2azJ8/n/bt27/V9yyEEEIIURyViOLxwIEDWvf18fHBx8fntf2cnZ1Zvnz5a/uZm5szfvx4xo8fr3UGIYQQQoj/q0rENY9CCCGEEKJ4kOJRCCGEEEJoTYpHIYQQQgihNSkehRBCCCGE1qR4FEIIIYQQWpPiUQghhBBCaE2KRyGEEEIIoTUpHoUQQgghhNakeBRCCCGEEFqT4lEIIYQQQmhNikchhBBCCKG1EvFsayGEeFPKlCuFmYmpzo/7LDuLlKRMnR9XCCHeNCkehRDvFDMTUzpGh+j8uDFdJ5KCFI9CiJJPpq2FEEIIIYTWpHgUQgghhBBak+JRCCGEEEJoTYpHIYQQQgihNSkehRBCCCGE1qR4FEIIIYQQWpPiUQghhBBCaE2KRyGEEEIIoTUpHoUQQgghhNakeBRCCCGEEFqTxxMKIUQxUKacGWYmJjo95rPsbFKSnun0mEKIkk+KRyGEKAbMTExw/+kHnR7zZ88vSEGKRyHEXyPT1kIIIYQQQmtSPAohhBBCCK1J8SiEEEIIIbQmxaOWUlJSCAkJwc3Njfr16+Pj48OxY8f0HUsIIYQQQqdkwYwWMjIy6NOnD+np6UyePBkbGxvWrl1Lv379+PHHH2ncuLG+IwohxBtXppw5Zia6/zHxLDuHlKQMnR9XCKEdKR61sG7dOi5evMjOnTupXr06ADNnziQhIYGwsDA2b96s34BCCPEWmJkY03lLlM6Pu72bByk6P6oQQltSPGphx44dNG/eXF04AhgYGODj48OoUaOIj4+nZs2aWu3L0NDgLaV8M4zKWOvluK/7XEpZqnSU5L9el6m0ZQUdJdH0qlxlLIpfJtvSxS+TqnRZHSb5r9f9m1KVttRRkv96fabSOkqiqahcllZmlNLDaGhmdg6pyXJbI/HueNW5wUBRFEWHWUqcrKwsXF1dGTJkCMOHD9fYdvv2bT7++GPmzJmDu7u7nhIKIYQQQuiOLJh5jadPn5KXl0f58uULbFOpno+GPXjwQNexhBBCCCH0QorH1zA2fj49YmBQ9PCtDN4KIYQQ4l0hxeNrWFtbY2pqyqNHjwpse/LkCQAVKujnmi4hhBBCCF2T4lELTk5OnDlzpkD7yZMn1duFEEIIId4FUjxqoWvXrhw+fJjbt29rtEdGRlK3bl0cHBz0lEwIIYQQQrdktbUWMjIy8PLyIjc3l7Fjx2Jtbc2GDRvYtm0bK1asoFmzZvqOKIQQQgihE1I8aunJkyeEhYVx8OBBnj17Rq1atQgKCqJp06b6jiaEEEIIoTNSPAohhBBCCK3JNY9CCCGEEEJrUjwKIYQQQgitSfEo/rbLly8zdepU6tevz7Zt2/QdRwghip3ieJ7UJtPTp09Zt24d7dq1o1+/fsUik65JpoJ0/3R58T9LSUlh/vz5HDhwgMTERGrVqsXIkSNp0qSJXvLcunWLL774guvXr6NSqcjIyNBLjpc9fPiQ8PBwfvvtNx48eEDlypXx8fGhb9++r3xS0Nv0xx9/sHjxYs6fP4+hoSEODg74+/vTpk0bveR5WWJiIl26dMHExIQDBw7oLccXX3zBb7/9VqC9atWq7N27Vw+Jnjty5AgLFy7k3LlzGBsb4+rqSlBQEHXr1tVLHjc3NxISEorcvnbtWr2cF86fP09ERASnTp0iPT2d6tWr4+Pjg6enJ0ZGRjrPA3D48GEWLlzI+fPnMTc3p3HjxowePZr3339fJ8f/K+fJHTt2sHz5cv78809sbW3x8vLC398fQ8M3O86jbaZx48axfft2TE1NMTAwoFKlSm80x/+SCWDTpk1s2LCB69evU6pUKT788EPGjBmDnZ2dXjIlJiYyb948fvnlF54+fYq9vT3u7u4MGDAACwsLvWR62cSJE4mMjGT16tVvZKGvFI8lREZGBn369CE9PZ3JkydjY2PD2rVr6devHz/++CONGzfWeSaVSkW3bt1o06YNZmZmfPzxxzrP8LKUlBT69u2LqakpX331FSqVikOHDhEWFkZWVhYDBw7Ueabdu3cTHBxMz549GTVqFABRUVEMGjSIb7/9Fk9PT51nepGiKIwZM+aN/4D6X9y5cwc/P78Cn4mpqameEsHBgwcZOXIkAQEBfPXVV6Snp7N27Vr8/PzYuXMntra2Os+0atUqsrOzC7R/9913xMfHU79+fZ1nOn36NL6+vtSvX5+wsDDKlCnD/v37mTx5MrGxsYSEhOg80++//46/vz8dOnRg1KhRZGdns3btWnr06EFUVBRVqlR56xm0PU8uXbqUBQsWEBgYSMuWLTl79iwzZswgISGBadOm6SVT8+bNcXd3p2nTpvj5+b3RDP9rprlz57J69WpGjBhBkyZNuH37Nt999x0DBgwgKioKExMTnWZ6+vQp3bp1w9ramilTplCpUiXOnTvHzJkzOXr0KGvWrHljebTN9LKff/650C/lf4siSoRly5Ypzs7Oyp9//qluy8vLU3r27Kl0795df8H+v1u3bimOjo7K1q1b9ZpjyZIlStOmTZXHjx9rtE+ZMkVp1KiRXjKtX79e+f777wu0+/j4KJ6ennpIpGnp0qWKm5ubsnbtWqVNmzZ6zeLq6qrs3LlTrxlelJGRobRo0UJZs2aNRntubq7y6NEjPaUqXHx8vOLi4qLs2bNHL8cPDg5WmjVrpqSnp2u0T5o0SXF2dlaSk5N1nsnT01Pp0aNHgfb+/fsrEyZM0Hmeos6T9+7dU2rXrq3MmzdPo33z5s2Ko6OjcvXqVZ1nelnv3r2Vvn37vrUc2mS6c+eO4uLiovz0008a7WfOnFEcHR3f6r/9ojJduHBBCQ4OVlJTUzXa8//urly5ovNML7px44bSsGFD5ZdfflEcHR2VI0eOvJFj63+oQWhlx44dNG/enOrVq6vbDAwM8PHx4cyZM8THx+svXDHSsmVLpk6dio2NjUZ7jRo1SElJITk5WeeZfHx8ihzx1Nc0er7Tp08zf/58QkJCMDc312uWxMREMjIyqFatml5zvGjfvn2kpKTQrVs3jXZDQ0O9jDi+ypw5c3B1deWTTz7Ry/GfPXtGlSpVCvw7cnZ2RlEUjI11P9F18eJFPvjggwLtbdu2ZdeuXeTk5Og8U2F27dpFbm4uXl5eGu2dO3emTJkyREdH6ylZ8WJmZsaYMWP47LPPNNpr1KgB8MpLOd4WZ2dn5syZU+T0tD7P8VlZWQQFBdG2bVs++uijN7pvKR5LgKysLC5dukSDBg0KbMufnrp48aKuYxVLderU4dNPP9Voy83NJSYmhqpVq2JlZaWnZM/l5ORw8+ZNQkJCOHHiBL6+vnrLkpyczMiRI/H19aV58+Z6y5Hvzp076v/6+vrSpEkT2rRpw9y5c8nKytJLpuPHj/P+++/z8OFDBg0aROPGjWnVqhUhISGkp6frJVNhzp07x969exkyZIjeMnz++edcvnyZa9euqdvy8vLYu3cvXl5eevlyUq5cOW7cuFGg/dq1a6SmpvLw4UOdZypMXFwc9vb22Nvba7SbmZlRq1YtLly4oKdkxYu1tTV9+/Yt8EVk+/btwPPzv74lJSWxY8cOvvvuO1q2bEnNmjX1liUsLIzk5GQmTZr0xvct1zyWAE+fPiUvL4/y5csX2KZSqQB48OCBrmOVCCkpKYwZM4azZ8+yaNEivWYJDw8nPDwcRVFo1KgRP/zwA61bt9Zbnq+++gobGxtGjhyptwwvyi8ev//+ewYOHIidnR3Hjx8nPDycK1euEBERofNMd+/eJTs7G39/f3r37k1AQACxsbHMmzeP27dvs2TJEp1nKsz333+Pi4sLrVq10luGdu3aoSgK48aN49NPP6Vy5crs3r0bd3d3vV3X6+XlRUREBKtWraJr167k5uaydetW9u/fDzxfXPdywaYPiYmJhZ7fAezs7Lhy5YqOE5UcmzdvJiQkhM8++0wv1/7nS0hIoG3btuTl5WFra4ufnx99+vTRW559+/axceNG1q9fj6Wl5RvfvxSPJUD+t6xXDX8r8qCgAmJjYwkODiY7O5uVK1fqbVV6Ph8fHz766CNu3LjBhg0bWLFiBdWrV+e9997TeZa1a9dy+PBhtm7d+kYvMP87atasyahRo/D19VWPUrm6umJtbc348eM5efIkDRs21GmmzMxM4uPjWbZsGR9++CEADRo0wNrami+//JITJ07QqFEjnWZ62fXr19m7dy9hYWF6zZGbm8u1a9dwcnKidevWVKhQgUuXLvHzzz9Tv359HBwcdJ5p2LBhGBoaMn/+fEJDQzE0NKRdu3aMHj2akSNH6nUh1otMTEyKPL/r+9KW4iotLY3JkycTExNDQEAAI0aM0GselUpFdHQ0jx494uDBg2zatInKlSvj7u6u8yx37tzhq6++IigoiHr16r2VY0jxWAJYW1tjamrKo0ePCmx78uQJABUqVNB1rGItOjqayZMn06lTJ8aNG0fZsmX1HQlbW1tsbW2pW7cu7du3p3///gQGBhIVFaXTHBcvXmTmzJlMnjyZChUqkJmZCTyfUlcUhczMTAwMDHT+g7VmzZqFTvHkryY8c+aMzotHKysrbGxs1IVjPjc3N+D5dKO+i8f169djYWFBu3bt9Jpj4sSJPH78mKVLl6rbAgMD+de//oWPjw87duzQ+XnK0NCQYcOGMXjwYO7cuYOVlRVly5Zl8+bNQPE5b6pUqiJHFxMTE9UzTOK5W7duERAQgKIobNiwQS93F3iZiYkJzs7OALRq1QpnZ2dGjx5NzZo11e26kJeXx6hRo3BycqJ3797q83u+7OxsMjMzMTEx+Vt32JBrHksIJycnzpw5U6D95MmT6u3iuaioKL7++mtmzJhBaGhosSgcX2ZsbEzbtm05d+4cqampOj32kSNHyMrKYuLEidSrV0/9a9KkSdy5c4d69erRvn17nWZ6lfzrHd/G1MvrODk5kZ2dXeTIvr5H/LOysti2bRvt27enVKlSesuRlpZGdHS0uqh+Ubt27UhOTtbrfTqNjIx477331OeC06dPU716daytrfWW6UVOTk7cvXu3wOVHOTk5xMbGyvn9Bffu3aNPnz44OzsTHR1dLArHwrRv3568vDyOHj2q0+OmpqZy8uRJ/vOf/+Dq6qpxjgfw8/OjXr16HDt27G8dR0YeS4iuXbsyffp0bt++rXFvssjISOrWrauXKaHi6OLFi0yZMoVZs2YVWDijD8nJyQQGBuLn51fgerTLly9TunTpN34T2ddxd3cv9IT7yy+/sGXLFsLDw/UynXf69GkOHjxIcHCwRvuuXbswNDTU+agjQIcOHQgPDycmJkZj+mnfvn0Aha7k1aUDBw6QlJSkl6mxFymKgoGBQaGjZ6dOnQLQy+URcXFx3Lt3j7Zt26rbHj58yK5duxg2bJjO8xTF3d2dGTNmsGXLFo1FTzExMaSmpuLh4aHHdMWHoigEBQVRq1YtZs+eXSym9JctW8b169eZPn26RvulS5cAdD5qbGFhwaZNmwrd1qNHDyZPnkzt2rX/ds0gxWMJ4eHhwcaNGxk4cCBjx47F2tqaDRs2cOTIEVasWKHveMXG7NmzcXV1xcHBodDbF6lUKsqUKaOzPFZWVlSsWJFhw4YREBBAy5YtycnJYd++ffz0008MHTpU5ydAOzu7Qp/EcO3aNUxNTfX2TT49PZ3ly5dz+fJl+vTpg4WFBf/+979ZvHgx3t7eelm1WKNGDfz8/Jg0aRLJyck0aNCA8+fPExoaSpcuXXBxcdF5phft378fMzMzvU+dW1pa0r17d9avX4+iKHTs2BFTU1NOnz5NeHg4VapUoUOHDjrPFRUVRWRkJEFBQbRo0YK7d+8yd+5cHB0d9Xqng5eVK1eOgIAAIiIiMDMzo3nz5sTFxakfIiCDA8/t3LmTs2fP8uOPP2qs6s9nbm7+Vp+CUxhnZ2cWLFhAUlISPj4+2NjYcOnSJebNm0fNmjX55z//qdM8RkZGrzyHOzg4vJFzvBSPJYS5uTmrV68mLCyMsWPH8uzZM2rVqsXKlSvfyKOG/q+Ij48nISGBjh07Fro9NDRU59/iQ0NDadiwIZGRkSxbtgxDQ0OqVavGt99+y+eff67TLMVZixYt2LhxIxEREQQHB5OamkrlypUZOnToW3+6xauMGjWKihUrsnr1aqZPn46NjQ29evXS+8hVXl4ev/32G40aNSoWCz+mTJlC7dq1iY6OZvv27WRlZVGxYkW8vLzw8/PTy22yJk2aRLVq1di4cSNz587FxsYGd3d3hg0bVmwWiuUbNmwYtra2rF69mrlz52JnZ4e/vz8BAQH6jlZsxMfHk5OTQ69evQrd/sEHH7zxJ7q8TuvWrYmMjGTJkiWMGzeO5ORk7O3tadu2LUOHDsXMzEyneXTFQNH3RTtCCCGEEKLEkAUzQgghhBBCa1I8CiGEEEIIrUnxKIQQQgghtCbFoxBCCCGE0JoUj0II8Tc8e/ZM3xGEEEKn5FY9QgjxGhs3bsTZ2bnA/dF+/fVXAgMDiYmJwdrampycHCwtLblz5w6fffYZBw8eVN9X9Nq1a1SrVg0jIyOtjjlixAjs7e0ZP378G38/2ti+fbvWhXGXLl20vl1Qbm6u1p+BEKJ4kuJRCPFOGTFiBLt3735ln/3796uf5BQbG8u0adOYMGGCRvGYlZXFrFmz8Pf3x97envDwcA4dOsSKFSvIy8sjJSWFn376iatXr3Ls2DEeP37M6NGj8fb2Vu9DURT14xdflpqaSlpaWoFn0+Z7248jnDFjBtbW1lo9/7lDhw5aFY+LFy9m7969On+euxDizZL7PAoh3imJiYmkp6cTFhYGwJgxY4iLiyMwMJD9+/cDULFiRYyNjUlISMDb2xsnJyeWLVumfhrQ1q1b+fe//82+ffsICAggMzOT5ORktmzZgoODAyEhIXTp0gVfX19q1aqFs7Mzzs7OHD58GCMjI1q2bAnA7du3+fjjj/+n93Ho0CEqVqxY5PYjR47wyy+/cPnyZZKSkjA1NaVGjRq4ubnh5uaGoeGrr1pq2bIlQUFBdO/e/X/KV5grV67QuXNnVq1aRbNmzdTtt27donTp0tja2r6xYwkh3h4ZeRRCvFNsbGywsbGhdOnSAFSpUoV79+6pf5/v8uXLDB48mPLlyzNv3jyNx0impaVha2tL//79KVWqFCqVChsbG7p3786mTZtITk4GoGHDhlSvXh1FUTh27BgRERG4uLioi8cqVaqon4H7Mj8/PypXrsy0adP+0vv7888/GTduHJcvX+ajjz7C0tKSo0ePMnnyZE6dOsWYMWOoWrUq8+fPp1q1aq/c18SJE5k4ceIr+4wfP55+/fpple0f//gHbdu2ZdGiRdSpU4fff/+d7du3c+DAATw9PQkJCdH2bQoh9EiKRyGEeEFeXh6bNm0iLCwMFxcXwsPDsbS0ZN++fXz44YeYmprSq1cvfH19efLkSYHXf/311zRu3BgPDw+WLFminnY2NTVFpVLh6emp0X///v0MHz680BwAW7ZsKbBt8eLFfPTRRwXaz5w5w4ABA2jSpAk7d+6kYsWKzJ49m0qVKuHl5YWXlxejRo1i1KhR9OjRg8jISN57770iP4vx48fz2WefvfLzsrCwKLQ9LS2Ne/fukZ2dTUZGBsnJydy+fZu8vDyOHj1Ks2bNKF26NM2bN2fevHm0adPmlccRQhQfUjwKIcQLtm3bxjfffEPfvn0JDg7G1NSUPXv2MGLECI3p1mvXrjFr1ixatGihfq2bmxupqanA81G7ogqrfJmZmbRq1YpTp04V2DZ48GAqVarEpEmTinzti9c9Pn78mMGDB9O2bVtCQ0PV09I3btzQKBDLly9PREQEHh4eTJw4kR9//FHLT+avSUtL4/PPP6dUqVKYm5tjY2NDpUqVqFy5Mk2aNOHJkyds27YNY2P5MSRESSP/1woh3hmKopCeng5ATk4OgMailLS0NNq1a0fdunVxcHAA4ObNm3z99dd4e3trXKcHsGjRIjZu3Kj+c2JiIgAJCQl8/PHHHDt2DCsrK9LS0jh06BANGjTA3t5effx69eq9NnNkZGSR286dO6cuvhYuXIi5uTlTp07VuJ4xLi6Ozp07a7zOwsKCPn36MG3aNG7evEnVqlUL3X9oaCihoaGvzFfUtLVKpeLs2bOFvubOnTt07NiRqKgovLy8Xrl/IUTxI8WjEOKdkV/UvWj79u3q3zds2BCAYcOGMXz4cO7fv0///v2pXr0648aNK7A/Dw8PjRXYL48gfvfdd1y9epVz585RsWJFvL296d+/PwDGxsacO3dO3TcpKYly5coBMHv2bM6ePcvKlSsxMDDg9OnT2NvbF1j5nF84ZmVlsWPHDgYNGoSZmZl6+71790hISMDV1bVA9vzC9dKlS0UWjyEhIW90wUy+SpUqMWjQIGbNmkWbNm2ws7N748cQQrw9UjwKId4Z9vb2/P777wB88803mJqaMnbsWK5evUq/fv3YtWsXlpaWlC5dmhMnThAYGIitrS1LliyhVKlSpKamYmlpqd7fokWL1AtvgALXQKpUKtzc3KhVqxYVKlTg6NGjHD9+nMaNGwP/Lf4yMzPx9vamTp061KhRg61bt/LDDz9gYmLCoUOHGD58OH5+fvj6+lKuXLkCK6Vv3rxJSkoKTZo00Wg/cOAApUqVKjBiCqhz54/EAjg5OWn00WbBzIuKWvwDz0d9Hz9+TGZmJjY2Nvj7+/PHH38wevRoVqxYIfd+FKIEkeJRCPHOMDIyUo9yZWVlYW9vj52dHY8ePQLA1taWnJwc5s6dy4YNG/jnP/9JWFgYFhYWrFu3jsWLFxMTE4OVlRXwfGSuRYsW3L9/HwsLC9q1a4ehoaG6uGvUqBH/+Mc/MDAwID4+niVLlqBSqdTFY75SpUqxfPlyhg4dys6dO1m3bh21a9cmJiaGcePGERAQwKBBg+jevTvW1tbMmTOHsmXLql+fv7r7xcIWIDo6mlatWmkUuPlu374NPC9w8x06dEj9+65du+Ln50enTp0AiIiIIC4ujoiICHWfvLw8Fi5cSJ06dYq85dDNmzdZtGgRu3bt0rjpuJ2dHXXq1OHgwYPMmTOHL7/8stDXCyGKH3k8oRDinZSUlFSg2ALYvXs3P//8M1OmTCE8PBwLCwvi4+OZNWsWHh4e6sLxRRMnTqRZs2bk5uZSs2ZNVCoVDRo0wN/fn5YtW9KiRQu6dOlCQkKCxvWHiYmJPHjwgPv372NiYkJYWBgODg6MHz+eBQsWMGrUKDw9PalduzZ79uzh008/5T//+Q89evTg/v376v3kF4D5BSE8n0KPjY3Fx8en0Pe/Y8cOSpUqpTGlXbFiRfUvQ0NDypYtq/7z4MGDuXbtGsePH6dixYqYm5szbdo09Q3VC7vnZGJiIt7e3qSlpbFmzRpOnDjB2bNn+f3335k1axbvv/8+1tbWxMTEqBcaCSGKP7lJuBDinZOXl0ejRo0ICQnB3d2dCxcu8Pnnn2sscMlfKX337l169uyJSqVizZo16iepnDt3jvLly1OhQgViY2OJjY3Fw8ODPn364O/vz6effgpAdnY2169fJykpqcC08pAhQ9Q3Js9nampK6dKlSUtLo1y5cjg5OVGmTBnKli1LuXLlKF++PHv27CEvL49169apX9ehQwdcXFyYPXs2eXl59OrVi6ysLLZs2aJxj0qAffv2MXz4cHx9fZkwYUKhn1FhNwlfvXo1s2fP5ssvv2TZsmXY29sza9asIm/3s3nzZkJDQzl27FiRq6pTU1PJzMyUG4QLUYLItLUQ4p1z/vx50tPTcXFxKXR7fuF448YNBg5onLBaAAAEJElEQVQciLm5OUuWLNF4BJ+VlRWffPIJ69ev5+TJk6xevZrevXvj7e1NcHAwYWFhdOrUCRMTE06cOEFoaChLly6ladOm6n3MnDmTjIwMTE1NycnJYcOGDXTo0AEHBwd8fX2pWrUq06dP58aNG8yYMYNGjRrRqVMnunTponGtIjx/7GJQUBBOTk5cu3aNs2fPsm7dOo3CMTU1leXLl7N06VJq167NyJEj/9Ln1rNnT65evco333yDm5sbixYteuWTaszNzXn27BmPHj0q8mk4lpaWhY4ACyGKL5m2FkK8czZu3IiLiwvvv/9+kX0OHjxIt27dMDc3Z+XKlVhbW2tsX7BgAdWqVaNOnToa7d26dWPIkCHq6yj9/PwwMzOjT58+DB06lOvXr6v7lilTBpVKxZ07d+jduzcxMTGFPiO6UqVKNG3alJCQEDp37qxevf2iDh06MGTIEObOncuePXsICwvD1dWVrKwsVq1axYgRI2jdujVLlizB09OTNWvWaKzMLkxWVhZHjx5lwYIFeHl5MXbsWKZOncqQIUM4ePAgwcHBXLt2rcjXf/LJJzg4ONC3b1+2bdtGfHw8KSkp5OTkkJuby9OnTwsUwUKIEkARQoh3yMWLF5U6deooP/30k7rt/PnziqOjo/L06VPl1q1bypAhQxRHR0clKChISU9PL7CPjRs3Ko6Ojsr+/fsVRVGUtWvXKq6ursoff/yhXLlyRbl69apy7tw5ZdeuXUr9+vWVDRs2KDk5OYq3t7fSqVMnJTMzU1EURYmPj1eGDx+uODs7K0FBQUpycrL6GL1791YmTJigcdxHjx4pX3zxheLo6KgsXry40Pf35MkT9f7zjR07VvHw8FDmzJmjXL9+vcjP5vHjx0p0dLQyffp0pW7duoqjo6PSoEEDZfjw4crWrVuVpKQkdd9jx44pXbp0UZycnJR+/fopmzdvLnSfKSkpyrx58xR3d3fF2dlZcXR01Pi1aNGiIvMIIYonmbYWQrxT1qxZQ5MmTejatWuh23Nzc7l79y6LFy/Gzc2t0D6GhoYMGDBAvb1169Zs3LiRgIAAnj17hoGBAaamppQtW5aGDRvSrl07jIyMCAsL48KFC+rRRSsrK0xMTFi9enWB6yELY2try9KlS4mOjuaTTz4ptE/+vSJfNGPGjNfuO/+9T58+ndq1azNw4EA++OAD6tevX+hoaOPGjYmOjubQoUNERkaSkJBQ6D4tLS0JDAwkMDCQ7OxskpKSyMjIICcnB2NjY2xsbLTKJoQoPmTBjBDinZKenk56ejrly5fXd5RiKS8v75XXMQohhBSPQgghhBBCa/L1UgghhBBCaE2KRyGEEEIIoTUpHoUQQgghhNakeBRCCCGEEFqT4lEIIYQQQmhNikchhBBCCKE1KR6FEEIIIYTW/h80Y2LUSCUKXgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np2tMLGvtOZ-",
        "colab_type": "text"
      },
      "source": [
        "文のベクトルを使って似た文を抽出してみましょう\n",
        "せっかくなので、たくさんの文章からベクトル化を使って意味の似た文章を抽出してみましょう。  \n",
        "まず、データを用意します。  \n",
        "京都大学の黒橋・河原研究室のホームページ(※1)から「Textual Entailment 評価データ」をダウンロードしてデータファイルを作ります。\n",
        "※１　https://bit.ly/2sXN2er"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2C-Asz9hLnV",
        "colab_type": "code",
        "outputId": "0ca50564-ab97-4ea5-e066-3663d4ff84cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/rte/entail_evaluation_set.xml -P /content/\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import codecs\n",
        "\n",
        "# 出力するファイルを指定\n",
        "f1 = codecs.open('T_plain.txt', 'w', 'utf-8')\n",
        "\n",
        "# XMLファイルからT1とT2の正例を抽出して、ファイルに出力\n",
        "corpus = ET.parse('entail_evaluation_set.xml')\n",
        "root = corpus.getroot()\n",
        "\n",
        "for child in root:\n",
        "  grandchild_text = {}\n",
        "  entail_tag = child.get('label')\n",
        "  for grandchild in child.getchildren():\n",
        "    grandchild_text[grandchild.tag] = grandchild.text\n",
        "  if entail_tag == '◎' or entail_tag == '〇':\n",
        "    f1.write(grandchild_text['t1']+\"\\n\")\n",
        "    f1.write(grandchild_text['t2']+\"\\n\") "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-11 05:33:13--  http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/rte/entail_evaluation_set.xml\n",
            "Resolving nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)... 133.3.252.171\n",
            "Connecting to nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)|133.3.252.171|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 461805 (451K) [text/xml]\n",
            "Saving to: ‘/content/entail_evaluation_set.xml.4’\n",
            "\n",
            "entail_evaluation_s 100%[===================>] 450.98K   197KB/s    in 2.3s    \n",
            "\n",
            "2020-04-11 05:33:16 (197 KB/s) - ‘/content/entail_evaluation_set.xml.4’ saved [461805/461805]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpg1DuNIpZFi",
        "colab_type": "text"
      },
      "source": [
        "どんな文が含まれているのか、10個ほどサンプリングして表示してみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5MOmBW0_IH6",
        "colab_type": "code",
        "outputId": "4246fefd-ddb4-4b6b-c03e-aa928fb8eb62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_table(\"/content/T_plain.txt\", header=None)\n",
        "df.sample(10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>昔は天動説が信じられていた。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>角館は東北にある。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>花子はお菓子が好きだ。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>売れ残ると困るので、店のお惣菜は夕方になると安くなる。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>枝豆を食べた。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>和歌を作った。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>もみじ狩りに行った。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>化粧は女を化かす。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>台風７号が発生し、日本に接近の恐れ。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>郵便局は銀行の左隣りにあります。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                0\n",
              "94                 昔は天動説が信じられていた。\n",
              "417                     角館は東北にある。\n",
              "29                    花子はお菓子が好きだ。\n",
              "1370  売れ残ると困るので、店のお惣菜は夕方になると安くなる。\n",
              "206                       枝豆を食べた。\n",
              "927                       和歌を作った。\n",
              "306                    もみじ狩りに行った。\n",
              "1034                    化粧は女を化かす。\n",
              "366            台風７号が発生し、日本に接近の恐れ。\n",
              "114              郵便局は銀行の左隣りにあります。"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtvu7sGXrp-9",
        "colab_type": "text"
      },
      "source": [
        "文例をいったんリスト化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHl21NG7PqA",
        "colab_type": "code",
        "outputId": "9b50496b-7766-4fe8-ecf9-dd0c1a9fc8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "sentences = df[0].values\n",
        "print(sentences)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['あの人は呼吸器専門医だ。' 'あの人は医者だ。' 'アメリカンショートヘアーを飼っている。' ...\n",
            " 'ボジョレ・ヌーヴォーの販売には解禁日がある。' '彼は英語が堪能である。' '彼の英語はうまい。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpG4MTawpirN",
        "colab_type": "text"
      },
      "source": [
        "実際に、日本語の文章がどのように形態素、さらにBERTの分析用のIDに変換されるのかを見てみてましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECWG30I-7kAr",
        "colab_type": "code",
        "outputId": "6ef03f94-4b6a-4925-dce1-72eaf8b7887e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print('原文: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('形態素: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('形態素に対応するID番号化: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原文:  あの人は呼吸器専門医だ。\n",
            "形態素:  ['あの', '人', 'は', '呼吸', '器', '専門', '##医', 'だ', '。']\n",
            "形態素に対応するID番号化:  [7755, 53, 9, 9489, 1777, 1534, 29205, 75, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIoQC5Txpthk",
        "colab_type": "text"
      },
      "source": [
        "文をBERTで分析する際、入力側の形態素数（≒単語数）を固定する必要があります。\n",
        "\n",
        "「Textual Entailment 評価データ」の形態素の数を見てみましょう。\n",
        "\n",
        "※CLS、SEPなどの特別な形態素も含めてカウントしています"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZhaoL1T71fF",
        "colab_type": "code",
        "outputId": "74bf9cc3-3d84-4534-da9a-0545a6afa7ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('最長の形態素数は⇒ ', max_len)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最長の形態素数は⇒  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjw9FwX9rTYi",
        "colab_type": "text"
      },
      "source": [
        "BERTモデルを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrkg0dNrDrgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdc4e3d4-b2e0-479c-fe61-22cd31da1055"
      },
      "source": [
        "from transformers import BertJapaneseTokenizer, BertModel\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "\n",
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "# This is IMPORTANT to have reproducible results during evaluation!\n",
        "# どうもpytorchには学習モードと推論モードがあるらしい。以下は推論モードに切り替え\n",
        "model.eval()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3CNYOOhrhq0",
        "colab_type": "text"
      },
      "source": [
        "文例を一気に形態素の順にID化します。ここでは同時に短い文例は32形態素になるよう０で残りを埋めています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM0JXUrn8E9l",
        "colab_type": "code",
        "outputId": "442616b0-07f6-48d9-87d6-c34eead8dd9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 32,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('attention_masks:', attention_masks[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  あの人は呼吸器専門医だ。\n",
            "Token IDs: tensor([    2,  7755,    53,     9,  9489,  1777,  1534, 29205,    75,     8,\n",
            "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "attention_masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoF0T-t4szbX",
        "colab_type": "text"
      },
      "source": [
        "ID化した文例をBERTモデルを使って形態素ごとにベクトル化し、アウトプットのテンソルの次元を確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxGxAw89MtVq",
        "colab_type": "code",
        "outputId": "e2874ea2-93b8-4118-938e-cd90ff7b30db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# GPU上で走らせるためには、関連するものをすべてGPU上に配置\n",
        "input_ids = input_ids.to('cuda')\n",
        "attention_masks = attention_masks.to('cuda')\n",
        "model.to('cuda')\n",
        "\n",
        "# いよいよ推論させる、というか各形態素に対応するベクトルを計算\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_masks)\n",
        "# 以下で素のアウトプット\n",
        "last_hidden_states = outputs[0]\n",
        "last_hidden_states.shape\n",
        "# last_hidden_states.type"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1848, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBS06vsLtpAt",
        "colab_type": "text"
      },
      "source": [
        "吐き出したテンソルのうち、CLSに相当するテンソルのみ切り出します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYgnjnGVM_7I",
        "colab_type": "code",
        "outputId": "d489b361-d913-48ca-d0d2-42e1198159f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# NumPy配列ndarrayの要素や部分配列（行・列など）は[2, 3, 1, ...]のように各次元の位置や範囲をカンマ区切りで指定。[:,0,:]でCLSに対応するはず\n",
        "last_hidden_states[:,0,:].shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1848, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT0h8Rost2jN",
        "colab_type": "text"
      },
      "source": [
        "例に似た文章をコサイン類似度を使って似ている順番に抽出します。まず、形態素×ID化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23qPqDdmAsXd",
        "colab_type": "code",
        "outputId": "bc6f8325-9509-4730-bbc1-c9677b3584d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# 例文と類似する文を探してみる\n",
        "example = '猫がニャーニャーとうるさくて眠れない。'\n",
        "\n",
        "# encode_plusでpaddingまでできる。超便利。ptでPyTorch、tfでTensorflow、何もつけないと普通にリストを返す\n",
        "example_ids = tokenizer.encode_plus(example, max_length=32, pad_to_max_length=True, return_tensors='pt')\n",
        "print(example_ids)\n",
        "type(example_ids)\n",
        "print(example_ids[\"input_ids\"]) #辞書から必要な部分を参照"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    2,  6040,    14,   353,   556,  5452, 28451,    13,  5619, 26079,\n",
            "            16,  8263, 28461,    80,     8,     3,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "tensor([[    2,  6040,    14,   353,   556,  5452, 28451,    13,  5619, 26079,\n",
            "            16,  8263, 28461,    80,     8,     3,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQPDIJHuH9T",
        "colab_type": "text"
      },
      "source": [
        "そのうえで、BERTを使ってベクトル化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO_cA1cMI85Q",
        "colab_type": "code",
        "outputId": "a8b86c9e-c457-4932-bd01-e9fcdc1f9427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# GPU上で走らせるためには、関連するものをすべてGPU上に配置\n",
        "input_ids_example = example_ids[\"input_ids\"].to('cuda')\n",
        "attention_masks_example = example_ids[\"attention_mask\"].to('cuda')\n",
        "model.to('cuda')\n",
        "\n",
        "# いよいよ推論させる、というか各形態素に対応するベクトルを計算\n",
        "with torch.no_grad():\n",
        "    example_outputs = model(input_ids_example, attention_mask=attention_masks_example)\n",
        "# 以下で素のアウトプット\n",
        "last_hidden_states_example = example_outputs[0]\n",
        "last_hidden_states_example[:,0,:].shape\n",
        "# last_hidden_states.type"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTErxLktuRRE",
        "colab_type": "text"
      },
      "source": [
        "コサイン類似度をすべて文例と計算し、上位20例を表示します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWezvQ4Ad2Kr",
        "colab_type": "code",
        "outputId": "e87985a1-7d34-496f-9f26-1b3f0501018e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "corpus = codecs.open('/content/T_plain.txt', 'r', 'utf-8')\n",
        "corpussimdic = {}\n",
        "\n",
        "# コサイン類似度を計算する\n",
        "def cos_sim(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "# 例文のベクトル\n",
        "example_vec = last_hidden_states_example[:,0,:].to('cpu').detach().numpy().copy()\n",
        "\n",
        "# コーパス文のベクトル\n",
        "corpus_vec = last_hidden_states[:,0,:].to('cpu').detach().numpy().copy() \n",
        "  \n",
        "print()\n",
        "print(example, \"<=>\")\n",
        "\n",
        "#\n",
        "# コーパスの文とのコサイン類似度を求める\n",
        "#\n",
        "i = 0\n",
        "for sentence in corpus:\n",
        "\n",
        "  corpussimdic[sentence.rstrip('\\n')] = cos_sim(example_vec, corpus_vec[i,:])\n",
        "  i += 1\n",
        "\n",
        "\n",
        "# valueで降順にソートしてトップ20の類似文を表示する\n",
        "count = 0\n",
        "for k, v in sorted(corpussimdic.items(), key=lambda x: -x[1]):\n",
        "    print(str(v) + \": \" + str(k)) \n",
        "    count += 1 \n",
        "    if count == 20:\n",
        "      break\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "猫がニャーニャーとうるさくて眠れない。 <=>\n",
            "[1.0000001]: 猫がニャーニャーとうるさくて眠れない。\n",
            "[0.94120175]: ニャーニャーとうるさくて眠れない。\n",
            "[0.8842278]: 何をやっても眠けがとれない。\n",
            "[0.87973124]: 何をしても眠い。\n",
            "[0.86993796]: おたふく風邪にかかると困る。\n",
            "[0.86776257]: あまりに眠くて、仕事にならない。\n",
            "[0.8653278]: ラブバードを見ていると、心がなごむ。\n",
            "[0.8635006]: ぼけると困る。\n",
            "[0.8615057]: ぴょんぴょん飛び跳ねるのはウサギだけではない。\n",
            "[0.8606796]: お昼だというのに、おなかがすかない。\n",
            "[0.855985]: 彼女は機嫌が悪い。\n",
            "[0.84726477]: 風で帽子がとんだ。\n",
            "[0.8444803]: おなかがすいた。\n",
            "[0.8398719]: 彼女は部屋のインテリアを気にする。\n",
            "[0.8396411]: 白い器に果物をのせているのが、おしゃれだ。\n",
            "[0.83810174]: さつきは緑に囲まれたマンションに住めてうらやましい。\n",
            "[0.8379033]: お金がない。\n",
            "[0.83746374]: 昨晩のおかずは和食だった。\n",
            "[0.83619326]: 彼女の夫は顔だちがいい。\n",
            "[0.83542836]: 虐待と間違われるのが怖くて、子供を叱れない。\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}